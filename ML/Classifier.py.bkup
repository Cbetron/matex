#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""pythonfile.py:	Description of pythonfile.py"""

__author__ = "Raphael Kreft"
__copyright__ = "Copyright (c) 2016 Raphael Kreft"
__version__ = "Development v0.0"
__email__ = "raphaelkreft@gmx.de"
__status__ = "Dev"

import pickle
import numpy
from operator import itemgetter
from ML.profile import Profile
from ML.vectors_matrix import *
from utils.textinit import *


class Classifier(object):
    def __init__(self, profile):
        self.cls_profile = profile.get_profile()
        # print("Actual Classprofile: \n{}".format(self.cls_profile))
        self.rating = self.cls_profile["rating"]

    def gen_muehvec(self, cls):
        muehvec = []
        for feature in sorted(self.cls_profile[str(cls)].keys()):
            if feature is not "covariancematrice" and feature is not "prior":
                muehvec.append(self.cls_profile[str(cls)][feature][0])
        return muehvec

    def cls_likelihood_multivariant(self, cls, valuevec):
        valuevec = valuevec.values()
        d = len(valuevec)
        mueh = self.gen_muehvec(cls)
        matrice = numpy.array(self.cls_profile[str(cls)]["covariancematrice"])
        if numpy.linalg.det(matrice) == 0:
            return
        return (1 / (2 * math.pi) ** (d / 2) * (numpy.linalg.det(matrice)) ** (1 / 2)) * math.e ** (
        -(1 / 2) * numpy.transpose((vector_sub(valuevec, mueh))) * numpy.linalg.inv(matrice) * (
        vector_sub(valuevec, mueh)))

    @staticmethod
    def feature_likelihood(value, mueh, nd, factor=1.0):
        return factor * (1 / (math.sqrt(2 * math.pi) * nd) * math.e ** (-0.5 * (float(value - mueh) / nd) ** 2))

    def cls_likelihood(self, cls, valuevec):
        likelyhood = 1.0
        forbidden = ['prior', 'covariancematrice', 'mueh', 'nd']
        for featurename in self.cls_profile[str(cls)].keys():
            if featurename in forbidden:
                continue
            singlelikelyhood = self.feature_likelihood(valuevec[featurename], *self.cls_profile[str(cls)][featurename])
            likelyhood *= singlelikelyhood
        return likelyhood

    def evidence(self, prior, valuevec, multivariant):
        """Evidence for one specific class"""
        evidence = 0
        for cls in self.rating:
            if multivariant:
                evidence += (prior * self.cls_likelihood_multivariant(cls, valuevec))
            else:
                evidence += (prior * self.cls_likelihood(cls, valuevec))
        return evidence

    def posterior(self, cls, valuevec, multivariant=True):
        """Gen the Posterior for one specific class"""
        # print("Make cls-profile for cls: {}".format(cls))
        if multivariant:
            lh = self.cls_likelihood_multivariant(cls, valuevec)
        else:
            lh = self.cls_likelihood(cls, valuevec)
        # print("Likelihood. {}".format(lh))
        prior = self.cls_profile[str(cls)]["prior"]
        # print("Prior: {}".format(prior))
        evidence = self.evidence(prior, valuevec, multivariant)
        # print("Evidence: {}".format(evidence))
        # print("Erg-wahrsch: {}".format(lh * prior / evidence))
        return lh * prior / evidence

    def classify(self, valuevec, multivariant=True):
        posterior_ergs = []
        for cls in self.rating:
            posterior_ergs.append((cls, self.posterior(cls, valuevec, multivariant)))
        most_common_class = max(posterior_ergs, key=itemgetter(1))[0]
        return most_common_class

    def set_profile(self, new_profile):
        self.cls_profile = new_profile.get_profile()


if __name__ == "__main__":
    with open("trainingsets/pickleddicts/kaggle_one_six.pkl", "rb") as dumbfile:
        dict_list = pickle.load(dumbfile)
    tsets, valsets = setsplit(dict_list, 0.7, 2, range(1, 7, 1))
    print("Make Profile object")
    myProfile = Profile("Test", tsets, dict_list, rating=range(1, 7, 1))
    print("Done!")
    print("Validation")
    result = 0
    MyClassifier = Classifier(myProfile)
    for valset in valsets:
        vec = valset["features"]
        grade = valset["grade"]
        Note = MyClassifier.classify(vec, multivariant=False)
        print("Note: {}".format(Note))
        print("Korrektor Note: {}".format(grade))
        if Note == grade:
            result += 1
    print("The Classifier classified {} from {} texts correct".format(result, len(valsets)))
